{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LianjiaTech/BELLE/blob/main/notebook/BELLE_INFER_COLAB.ipynb) "
      ],
      "metadata": {
        "id": "7m81oxz-sGgM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p70s1UElROWa"
      },
      "source": [
        "# ** BELLE模型在COLAB推理的示例** \n",
        "这里提供在colab环境运行BELLE模型的代码。默认加载的是4bit量化的llama模型，在模型加载到内存过程中，最高消费RAM大概需要7G，等模型load到GPU中以后，RAM只需要4G，GPU大概需要6G。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUt9JenaRViP"
      },
      "source": [
        "## 查看colab分配的显卡类型，一般免费账户上14G的T4显卡"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORaFqtT6QV4c"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLwfc3zuPqmK",
        "outputId": "cf589657-4228-4aa6-c610-65e976903974"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Apr  6 04:03:10 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   75C    P8    11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8ZvOYEKRl-N"
      },
      "source": [
        "##  将BELLE项目git clone到colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zSYeftDDS3l",
        "outputId": "02b90ee0-175d-45f1-eb7f-8a27b14f8817"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'BELLE' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/LianjiaTech/BELLE.git "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u8KiaitR3Yt"
      },
      "source": [
        "### 14G显卡目前只支持量化版本，这里暂时只提供量化版本在colab推理"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEzcL3t7DkAW",
        "outputId": "d32fb504-7254-4195-fcf0-4b1cbd0bf0ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/BELLE/gptq\n"
          ]
        }
      ],
      "source": [
        "%cd BELLE/gptq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpGt4F3BSLW-"
      },
      "source": [
        "### 安装gptq环境"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wd9frauTDx8t",
        "outputId": "4f4ab860-d6fe-4a27-d931-fb976f1e93e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/',\n",
              " 'Collecting git+https://github.com/huggingface/transformers (from -r requirements.txt (line 4))',\n",
              " '  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-zup77i5e',\n",
              " '  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-zup77i5e',\n",
              " '  Resolved https://github.com/huggingface/transformers to commit 15641892985b1d77acc74c9065c332cd7c3f7d7f',\n",
              " '  Installing build dependencies ... \\x1b[?25l\\x1b[?25hdone',\n",
              " '  Getting requirements to build wheel ... \\x1b[?25l\\x1b[?25hdone',\n",
              " '  Installing backend dependencies ... \\x1b[?25l\\x1b[?25hdone',\n",
              " '  Preparing metadata (pyproject.toml) ... \\x1b[?25l\\x1b[?25hdone',\n",
              " 'Requirement already satisfied: safetensors==0.3.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 1)) (0.3.0)',\n",
              " 'Requirement already satisfied: datasets==2.10.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 2)) (2.10.1)',\n",
              " 'Requirement already satisfied: sentencepiece in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 3)) (0.1.97)',\n",
              " 'Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (2023.3.0)',\n",
              " 'Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (1.22.4)',\n",
              " 'Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (4.65.0)',\n",
              " 'Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.9/dist-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (0.13.3)',\n",
              " 'Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (1.4.4)',\n",
              " 'Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (2.27.1)',\n",
              " 'Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (3.2.0)',\n",
              " 'Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (23.0)',\n",
              " 'Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (0.18.0)',\n",
              " 'Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (6.0)',\n",
              " 'Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (0.70.14)',\n",
              " 'Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (3.8.4)',\n",
              " 'Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (0.3.6)',\n",
              " 'Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (9.0.0)',\n",
              " 'Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0->-r requirements.txt (line 4)) (3.10.7)',\n",
              " 'Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0->-r requirements.txt (line 4)) (2022.10.31)',\n",
              " 'Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0->-r requirements.txt (line 4)) (0.13.3)',\n",
              " 'Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets==2.10.1->-r requirements.txt (line 2)) (1.3.3)',\n",
              " 'Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets==2.10.1->-r requirements.txt (line 2)) (22.2.0)',\n",
              " 'Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets==2.10.1->-r requirements.txt (line 2)) (1.8.2)',\n",
              " 'Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets==2.10.1->-r requirements.txt (line 2)) (2.0.12)',\n",
              " 'Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets==2.10.1->-r requirements.txt (line 2)) (4.0.2)',\n",
              " 'Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets==2.10.1->-r requirements.txt (line 2)) (6.0.4)',\n",
              " 'Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets==2.10.1->-r requirements.txt (line 2)) (1.3.1)',\n",
              " 'Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets==2.10.1->-r requirements.txt (line 2)) (4.5.0)',\n",
              " 'Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets==2.10.1->-r requirements.txt (line 2)) (3.4)',\n",
              " 'Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets==2.10.1->-r requirements.txt (line 2)) (2022.12.7)',\n",
              " 'Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets==2.10.1->-r requirements.txt (line 2)) (1.26.15)',\n",
              " 'Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets==2.10.1->-r requirements.txt (line 2)) (2022.7.1)',\n",
              " 'Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets==2.10.1->-r requirements.txt (line 2)) (2.8.2)',\n",
              " 'Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->datasets==2.10.1->-r requirements.txt (line 2)) (1.16.0)']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCSRFoAcsE9r"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y  transformers\n",
        "!pip install  git+https://github.com/huggingface/transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wT0Gq7tkEWs6",
        "outputId": "6d19b70a-ff7f-40ba-859b-a2621b4fc990"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running install\n",
            "/usr/local/lib/python3.9/dist-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/setuptools/command/easy_install.py:144: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
            "  warnings.warn(\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing quant_cuda.egg-info/PKG-INFO\n",
            "writing dependency_links to quant_cuda.egg-info/dependency_links.txt\n",
            "writing top-level names to quant_cuda.egg-info/top_level.txt\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "reading manifest file 'quant_cuda.egg-info/SOURCES.txt'\n",
            "writing manifest file 'quant_cuda.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_ext\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/cpp_extension.py:398: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 11.8\n",
            "  warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-3.9/quant_cuda.cpython-39-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "creating stub loader for quant_cuda.cpython-39-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/quant_cuda.py to quant_cuda.cpython-39.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying quant_cuda.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying quant_cuda.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying quant_cuda.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying quant_cuda.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.quant_cuda.cpython-39: module references __file__\n",
            "creating 'dist/quant_cuda-0.0.0-py3.9-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing quant_cuda-0.0.0-py3.9-linux-x86_64.egg\n",
            "removing '/usr/local/lib/python3.9/dist-packages/quant_cuda-0.0.0-py3.9-linux-x86_64.egg' (and everything under it)\n",
            "creating /usr/local/lib/python3.9/dist-packages/quant_cuda-0.0.0-py3.9-linux-x86_64.egg\n",
            "Extracting quant_cuda-0.0.0-py3.9-linux-x86_64.egg to /usr/local/lib/python3.9/dist-packages\n",
            "quant-cuda 0.0.0 is already the active version in easy-install.pth\n",
            "\n",
            "Installed /usr/local/lib/python3.9/dist-packages/quant_cuda-0.0.0-py3.9-linux-x86_64.egg\n",
            "Processing dependencies for quant-cuda==0.0.0\n",
            "Finished processing dependencies for quant-cuda==0.0.0\n",
            "Benchmarking LLaMa-7B FC2 matvec ...\n",
            "FP16: 0.0004962031841278076\n",
            "2bit: 0.0012085423469543456\n",
            "3bit: 0.0009770829677581787\n",
            "4bit: 0.0009206428527832032\n",
            "8bit: 0.0007652266025543213\n",
            "Verifiying kernel correctness ...\n",
            "2bit Simu: tensor([[[-2.9546e-01,  1.2915e-01, -4.3734e-01,  ...,  6.0990e-01,\n",
            "           2.4561e-01,  7.0003e-01],\n",
            "         [-1.4049e-01, -6.8034e-01, -4.3828e-01,  ...,  3.5179e-01,\n",
            "           4.4231e-01, -3.5731e-01],\n",
            "         [ 3.3377e-01, -2.7172e-01, -1.0256e+00,  ..., -3.9233e-01,\n",
            "           1.2670e+00,  7.1985e-01],\n",
            "         ...,\n",
            "         [ 3.5666e-02, -3.4819e-01,  1.7624e-01,  ...,  1.4410e+00,\n",
            "           6.6767e-01,  1.9720e-01],\n",
            "         [-2.3046e-02,  8.5493e-01, -9.8487e-02,  ..., -6.5159e-02,\n",
            "           5.4727e-01, -7.0733e-03],\n",
            "         [-1.5612e-01,  3.9877e-01,  6.0892e-01,  ..., -6.8541e-02,\n",
            "          -1.9368e+00, -2.8755e-01]],\n",
            "\n",
            "        [[ 1.1804e-01, -2.1816e-01, -7.8529e-01,  ..., -2.0083e-01,\n",
            "           4.7985e-01, -2.7876e-01],\n",
            "         [ 9.5314e-01, -6.1527e-01,  7.5435e-01,  ..., -6.7251e-01,\n",
            "          -1.0138e+00,  4.1647e-04],\n",
            "         [-1.3141e-01, -9.0353e-01,  5.0451e-01,  ...,  2.4873e-01,\n",
            "          -9.9160e-02, -5.4755e-01],\n",
            "         ...,\n",
            "         [-2.7803e-01, -1.3162e-01, -3.7418e-01,  ...,  3.5528e-01,\n",
            "          -1.3073e+00,  4.3653e-01],\n",
            "         [-9.2877e-02, -5.2455e-01,  5.1692e-01,  ...,  7.5895e-02,\n",
            "           4.4102e-01,  9.4174e-01],\n",
            "         [-8.1485e-02,  4.0748e-01, -6.6200e-01,  ...,  3.3834e-01,\n",
            "           2.9176e-01, -1.7804e-01]],\n",
            "\n",
            "        [[ 2.2561e-01, -6.9830e-01,  7.8079e-01,  ..., -7.5449e-01,\n",
            "          -5.1139e-01, -7.9411e-01],\n",
            "         [-1.0935e+00,  8.4212e-02,  1.4571e-01,  ...,  8.6397e-01,\n",
            "          -5.3775e-01,  8.7618e-01],\n",
            "         [ 2.0901e-01, -1.7989e-01,  3.3742e-01,  ...,  1.0149e+00,\n",
            "           3.4627e-02,  5.7534e-01],\n",
            "         ...,\n",
            "         [-1.6526e-01, -7.3907e-01, -2.7973e-01,  ...,  6.9786e-01,\n",
            "           2.9070e-01, -1.1267e+00],\n",
            "         [-3.0361e-01, -4.5548e-01,  4.0858e-01,  ...,  3.5867e-01,\n",
            "          -7.2021e-01,  4.6312e-01],\n",
            "         [-4.1507e-01,  1.2779e+00,  2.2585e-01,  ..., -1.1595e-01,\n",
            "          -8.3233e-01, -1.1874e-01]],\n",
            "\n",
            "        [[ 4.8745e-01, -9.9917e-01, -4.0095e-01,  ...,  3.0591e-01,\n",
            "          -1.1181e-01, -3.7905e-01],\n",
            "         [ 2.5070e-01, -5.9936e-01, -5.8809e-01,  ...,  1.3065e+00,\n",
            "          -5.6969e-01, -9.9019e-02],\n",
            "         [ 8.8164e-01,  4.0919e-01,  4.2243e-01,  ..., -1.2269e+00,\n",
            "           7.5386e-01,  2.3879e-01],\n",
            "         ...,\n",
            "         [-6.5608e-01, -7.7490e-01, -4.8143e-01,  ...,  5.2061e-01,\n",
            "           5.0159e-01, -2.3148e-01],\n",
            "         [-6.1364e-03, -2.5789e-01,  5.7401e-01,  ...,  6.7782e-01,\n",
            "           2.1711e-01,  2.1270e-01],\n",
            "         [ 1.0361e-01,  4.2014e-01, -2.4195e-01,  ...,  3.3209e-01,\n",
            "           3.1753e-01,  6.6446e-01]],\n",
            "\n",
            "        [[-4.1751e-01,  2.1563e-01, -7.9825e-01,  ...,  4.0323e-01,\n",
            "          -8.6754e-01,  2.5979e-01],\n",
            "         [-3.3745e-01, -1.0915e+00, -1.0591e-01,  ..., -7.8634e-01,\n",
            "           8.9702e-01,  1.0972e-01],\n",
            "         [ 3.5833e-01,  4.0164e-03,  6.2999e-01,  ..., -5.9821e-01,\n",
            "           4.9826e-02, -2.0416e-01],\n",
            "         ...,\n",
            "         [ 6.7009e-01,  2.8842e-01, -4.1819e-01,  ..., -7.3393e-01,\n",
            "          -5.8099e-01,  2.8323e-01],\n",
            "         [-1.7152e-01, -1.5227e-01,  4.7494e-01,  ..., -3.2847e-01,\n",
            "           5.3142e-01, -2.0841e-01],\n",
            "         [-7.3989e-02, -6.4349e-01,  8.6356e-02,  ...,  5.9895e-01,\n",
            "          -4.4979e-01, -1.9365e-01]]], device='cuda:0')\n",
            "2bit Kern: tensor([[[-2.9546e-01,  1.2915e-01, -4.3734e-01,  ...,  6.0990e-01,\n",
            "           2.4561e-01,  7.0003e-01],\n",
            "         [-1.4049e-01, -6.8034e-01, -4.3828e-01,  ...,  3.5179e-01,\n",
            "           4.4231e-01, -3.5731e-01],\n",
            "         [ 3.3377e-01, -2.7172e-01, -1.0256e+00,  ..., -3.9233e-01,\n",
            "           1.2670e+00,  7.1985e-01],\n",
            "         ...,\n",
            "         [ 3.5666e-02, -3.4819e-01,  1.7624e-01,  ...,  1.4410e+00,\n",
            "           6.6767e-01,  1.9720e-01],\n",
            "         [-2.3046e-02,  8.5494e-01, -9.8487e-02,  ..., -6.5159e-02,\n",
            "           5.4727e-01, -7.0732e-03],\n",
            "         [-1.5612e-01,  3.9877e-01,  6.0892e-01,  ..., -6.8541e-02,\n",
            "          -1.9368e+00, -2.8755e-01]],\n",
            "\n",
            "        [[ 1.1804e-01, -2.1816e-01, -7.8529e-01,  ..., -2.0083e-01,\n",
            "           4.7985e-01, -2.7876e-01],\n",
            "         [ 9.5314e-01, -6.1527e-01,  7.5435e-01,  ..., -6.7251e-01,\n",
            "          -1.0138e+00,  4.1637e-04],\n",
            "         [-1.3141e-01, -9.0353e-01,  5.0451e-01,  ...,  2.4873e-01,\n",
            "          -9.9160e-02, -5.4755e-01],\n",
            "         ...,\n",
            "         [-2.7803e-01, -1.3162e-01, -3.7418e-01,  ...,  3.5528e-01,\n",
            "          -1.3073e+00,  4.3653e-01],\n",
            "         [-9.2877e-02, -5.2455e-01,  5.1692e-01,  ...,  7.5894e-02,\n",
            "           4.4102e-01,  9.4174e-01],\n",
            "         [-8.1485e-02,  4.0748e-01, -6.6200e-01,  ...,  3.3834e-01,\n",
            "           2.9176e-01, -1.7804e-01]],\n",
            "\n",
            "        [[ 2.2561e-01, -6.9830e-01,  7.8079e-01,  ..., -7.5449e-01,\n",
            "          -5.1139e-01, -7.9411e-01],\n",
            "         [-1.0935e+00,  8.4212e-02,  1.4571e-01,  ...,  8.6397e-01,\n",
            "          -5.3775e-01,  8.7618e-01],\n",
            "         [ 2.0901e-01, -1.7989e-01,  3.3742e-01,  ...,  1.0149e+00,\n",
            "           3.4627e-02,  5.7535e-01],\n",
            "         ...,\n",
            "         [-1.6526e-01, -7.3907e-01, -2.7973e-01,  ...,  6.9786e-01,\n",
            "           2.9070e-01, -1.1267e+00],\n",
            "         [-3.0361e-01, -4.5548e-01,  4.0858e-01,  ...,  3.5867e-01,\n",
            "          -7.2021e-01,  4.6312e-01],\n",
            "         [-4.1507e-01,  1.2779e+00,  2.2585e-01,  ..., -1.1595e-01,\n",
            "          -8.3233e-01, -1.1874e-01]],\n",
            "\n",
            "        [[ 4.8745e-01, -9.9917e-01, -4.0095e-01,  ...,  3.0591e-01,\n",
            "          -1.1181e-01, -3.7905e-01],\n",
            "         [ 2.5070e-01, -5.9936e-01, -5.8809e-01,  ...,  1.3065e+00,\n",
            "          -5.6969e-01, -9.9019e-02],\n",
            "         [ 8.8164e-01,  4.0919e-01,  4.2243e-01,  ..., -1.2269e+00,\n",
            "           7.5386e-01,  2.3879e-01],\n",
            "         ...,\n",
            "         [-6.5608e-01, -7.7490e-01, -4.8143e-01,  ...,  5.2062e-01,\n",
            "           5.0159e-01, -2.3148e-01],\n",
            "         [-6.1363e-03, -2.5789e-01,  5.7401e-01,  ...,  6.7782e-01,\n",
            "           2.1711e-01,  2.1270e-01],\n",
            "         [ 1.0361e-01,  4.2014e-01, -2.4195e-01,  ...,  3.3210e-01,\n",
            "           3.1753e-01,  6.6445e-01]],\n",
            "\n",
            "        [[-4.1751e-01,  2.1563e-01, -7.9825e-01,  ...,  4.0322e-01,\n",
            "          -8.6754e-01,  2.5979e-01],\n",
            "         [-3.3745e-01, -1.0915e+00, -1.0591e-01,  ..., -7.8634e-01,\n",
            "           8.9702e-01,  1.0972e-01],\n",
            "         [ 3.5833e-01,  4.0167e-03,  6.2999e-01,  ..., -5.9821e-01,\n",
            "           4.9826e-02, -2.0416e-01],\n",
            "         ...,\n",
            "         [ 6.7009e-01,  2.8842e-01, -4.1819e-01,  ..., -7.3393e-01,\n",
            "          -5.8099e-01,  2.8323e-01],\n",
            "         [-1.7152e-01, -1.5227e-01,  4.7494e-01,  ..., -3.2847e-01,\n",
            "           5.3142e-01, -2.0841e-01],\n",
            "         [-7.3989e-02, -6.4349e-01,  8.6356e-02,  ...,  5.9895e-01,\n",
            "          -4.4979e-01, -1.9365e-01]]], device='cuda:0')\n",
            "\n",
            "\n",
            "3bit Simu: tensor([[[ 1.6592e-01, -9.9838e-01, -3.0194e-02,  ...,  4.6932e-01,\n",
            "          -1.1606e+00,  7.0915e-01],\n",
            "         [-4.4347e-01,  2.0302e-02, -5.1193e-01,  ..., -4.4474e-01,\n",
            "          -1.8215e-01,  4.1423e-02],\n",
            "         [-3.1734e-01, -4.3135e-01, -5.3153e-01,  ...,  4.2461e-01,\n",
            "          -8.5778e-01, -1.2003e+00],\n",
            "         ...,\n",
            "         [ 3.9887e-01, -3.7417e-01,  1.4179e-01,  ...,  6.0487e-01,\n",
            "          -1.1320e-01,  7.4185e-01],\n",
            "         [-4.0547e-04, -5.2160e-01,  4.5290e-02,  ...,  9.2487e-01,\n",
            "           1.9448e-01,  1.0161e+00],\n",
            "         [-7.5079e-01,  5.8806e-01, -2.6159e-01,  ...,  8.8855e-01,\n",
            "           2.7308e-01,  7.6636e-02]],\n",
            "\n",
            "        [[-7.6679e-01, -5.8459e-01,  1.9255e-01,  ...,  2.7737e-01,\n",
            "          -1.6652e-01,  4.9363e-01],\n",
            "         [ 1.4042e+00,  3.6487e-01,  1.5685e-02,  ..., -4.4323e-01,\n",
            "          -1.0695e-01,  8.8496e-03],\n",
            "         [ 2.0948e-01, -1.6514e-01,  7.2378e-01,  ...,  3.6651e-01,\n",
            "          -4.4284e-01, -1.3233e-01],\n",
            "         ...,\n",
            "         [-2.6879e-01,  1.7274e-01,  8.7373e-01,  ..., -2.9754e-01,\n",
            "           4.8703e-02, -8.8013e-01],\n",
            "         [-5.5025e-01, -6.1321e-01,  4.4733e-01,  ..., -7.0576e-01,\n",
            "          -6.3305e-01, -3.7414e-01],\n",
            "         [-6.1936e-01, -3.4838e-01, -1.2305e+00,  ..., -4.3352e-02,\n",
            "           2.3776e-01,  4.2346e-01]],\n",
            "\n",
            "        [[-1.5084e-01,  1.0236e+00,  7.3106e-01,  ..., -1.6102e-01,\n",
            "          -6.4221e-01, -8.2135e-02],\n",
            "         [-2.8528e-01,  5.4474e-01,  2.9608e-01,  ..., -3.2729e-01,\n",
            "          -2.3851e-01, -9.4277e-02],\n",
            "         [ 5.3865e-01,  4.2499e-01,  4.4535e-01,  ..., -3.3511e-01,\n",
            "           2.2920e-01, -1.5448e-01],\n",
            "         ...,\n",
            "         [ 3.7420e-01, -3.2622e-01, -6.4747e-01,  ...,  1.8523e-01,\n",
            "          -4.7982e-01, -7.2512e-01],\n",
            "         [-1.0300e-01, -1.8979e-01, -1.1067e-01,  ..., -3.9119e-01,\n",
            "          -2.1390e-01,  5.0876e-01],\n",
            "         [-1.5324e+00, -1.4803e+00, -5.5718e-01,  ...,  1.5779e-01,\n",
            "          -2.1029e-01, -2.1941e-03]],\n",
            "\n",
            "        [[ 8.0450e-01,  3.4015e-02, -1.8156e-01,  ..., -7.2730e-01,\n",
            "          -3.3162e-01,  3.1632e-01],\n",
            "         [-3.0828e-03,  8.9688e-01,  3.2038e-01,  ..., -1.0658e+00,\n",
            "           1.6298e-02, -1.0121e+00],\n",
            "         [ 2.0919e-01, -3.9686e-01, -5.8332e-01,  ..., -2.2853e-02,\n",
            "          -5.5627e-01, -5.2715e-01],\n",
            "         ...,\n",
            "         [-8.1665e-01, -3.3437e-01,  1.6960e-01,  ...,  3.9081e-01,\n",
            "          -7.6586e-01, -9.0626e-01],\n",
            "         [ 1.0123e+00,  3.2973e-01, -2.3055e-01,  ...,  3.1804e-01,\n",
            "          -1.9331e-01, -7.7443e-01],\n",
            "         [ 5.4322e-01,  4.4985e-01, -2.6630e-01,  ..., -2.8536e-01,\n",
            "           3.6778e-01,  3.6572e-01]],\n",
            "\n",
            "        [[ 9.0154e-01,  5.8080e-01,  2.7722e-01,  ...,  1.1499e-01,\n",
            "          -3.4998e-01,  1.0655e-01],\n",
            "         [-1.8558e-01, -7.8653e-02, -2.3082e-01,  ...,  4.3888e-02,\n",
            "          -1.4241e+00,  2.9938e-01],\n",
            "         [-1.1184e-01, -8.0151e-01,  2.8811e-01,  ..., -5.2816e-01,\n",
            "          -9.8755e-01, -4.2968e-02],\n",
            "         ...,\n",
            "         [ 1.7752e-01,  6.0683e-01, -1.7989e-01,  ..., -1.1998e+00,\n",
            "          -1.6638e-01,  2.7012e-02],\n",
            "         [-5.2442e-01,  4.2906e-01, -2.3205e-01,  ..., -2.2718e-01,\n",
            "           1.2725e+00,  6.7703e-01],\n",
            "         [ 3.2405e-01,  9.4774e-01, -9.3867e-02,  ..., -6.7912e-01,\n",
            "           1.1141e+00,  2.8494e-01]]], device='cuda:0')\n",
            "3bit Kern: tensor([[[ 1.6592e-01, -9.9838e-01, -3.0193e-02,  ...,  4.6932e-01,\n",
            "          -1.1606e+00,  7.0916e-01],\n",
            "         [-4.4347e-01,  2.0303e-02, -5.1193e-01,  ..., -4.4474e-01,\n",
            "          -1.8215e-01,  4.1423e-02],\n",
            "         [-3.1734e-01, -4.3135e-01, -5.3153e-01,  ...,  4.2461e-01,\n",
            "          -8.5778e-01, -1.2003e+00],\n",
            "         ...,\n",
            "         [ 3.9887e-01, -3.7417e-01,  1.4179e-01,  ...,  6.0487e-01,\n",
            "          -1.1320e-01,  7.4185e-01],\n",
            "         [-4.0566e-04, -5.2159e-01,  4.5290e-02,  ...,  9.2487e-01,\n",
            "           1.9448e-01,  1.0161e+00],\n",
            "         [-7.5079e-01,  5.8806e-01, -2.6159e-01,  ...,  8.8856e-01,\n",
            "           2.7308e-01,  7.6636e-02]],\n",
            "\n",
            "        [[-7.6678e-01, -5.8459e-01,  1.9255e-01,  ...,  2.7737e-01,\n",
            "          -1.6652e-01,  4.9363e-01],\n",
            "         [ 1.4042e+00,  3.6487e-01,  1.5685e-02,  ..., -4.4323e-01,\n",
            "          -1.0695e-01,  8.8497e-03],\n",
            "         [ 2.0948e-01, -1.6514e-01,  7.2378e-01,  ...,  3.6651e-01,\n",
            "          -4.4284e-01, -1.3233e-01],\n",
            "         ...,\n",
            "         [-2.6879e-01,  1.7274e-01,  8.7373e-01,  ..., -2.9754e-01,\n",
            "           4.8703e-02, -8.8013e-01],\n",
            "         [-5.5025e-01, -6.1321e-01,  4.4733e-01,  ..., -7.0576e-01,\n",
            "          -6.3305e-01, -3.7414e-01],\n",
            "         [-6.1936e-01, -3.4838e-01, -1.2305e+00,  ..., -4.3352e-02,\n",
            "           2.3776e-01,  4.2346e-01]],\n",
            "\n",
            "        [[-1.5084e-01,  1.0236e+00,  7.3106e-01,  ..., -1.6102e-01,\n",
            "          -6.4221e-01, -8.2136e-02],\n",
            "         [-2.8528e-01,  5.4474e-01,  2.9608e-01,  ..., -3.2729e-01,\n",
            "          -2.3851e-01, -9.4276e-02],\n",
            "         [ 5.3865e-01,  4.2499e-01,  4.4535e-01,  ..., -3.3511e-01,\n",
            "           2.2920e-01, -1.5448e-01],\n",
            "         ...,\n",
            "         [ 3.7420e-01, -3.2622e-01, -6.4747e-01,  ...,  1.8523e-01,\n",
            "          -4.7982e-01, -7.2512e-01],\n",
            "         [-1.0300e-01, -1.8979e-01, -1.1067e-01,  ..., -3.9119e-01,\n",
            "          -2.1390e-01,  5.0876e-01],\n",
            "         [-1.5324e+00, -1.4803e+00, -5.5718e-01,  ...,  1.5779e-01,\n",
            "          -2.1029e-01, -2.1941e-03]],\n",
            "\n",
            "        [[ 8.0450e-01,  3.4015e-02, -1.8156e-01,  ..., -7.2731e-01,\n",
            "          -3.3162e-01,  3.1632e-01],\n",
            "         [-3.0830e-03,  8.9688e-01,  3.2038e-01,  ..., -1.0658e+00,\n",
            "           1.6299e-02, -1.0121e+00],\n",
            "         [ 2.0919e-01, -3.9686e-01, -5.8332e-01,  ..., -2.2853e-02,\n",
            "          -5.5627e-01, -5.2715e-01],\n",
            "         ...,\n",
            "         [-8.1665e-01, -3.3437e-01,  1.6960e-01,  ...,  3.9082e-01,\n",
            "          -7.6586e-01, -9.0626e-01],\n",
            "         [ 1.0123e+00,  3.2973e-01, -2.3054e-01,  ...,  3.1804e-01,\n",
            "          -1.9331e-01, -7.7443e-01],\n",
            "         [ 5.4322e-01,  4.4985e-01, -2.6630e-01,  ..., -2.8536e-01,\n",
            "           3.6778e-01,  3.6572e-01]],\n",
            "\n",
            "        [[ 9.0154e-01,  5.8080e-01,  2.7722e-01,  ...,  1.1499e-01,\n",
            "          -3.4998e-01,  1.0655e-01],\n",
            "         [-1.8558e-01, -7.8652e-02, -2.3082e-01,  ...,  4.3888e-02,\n",
            "          -1.4241e+00,  2.9938e-01],\n",
            "         [-1.1184e-01, -8.0151e-01,  2.8811e-01,  ..., -5.2816e-01,\n",
            "          -9.8755e-01, -4.2968e-02],\n",
            "         ...,\n",
            "         [ 1.7752e-01,  6.0683e-01, -1.7989e-01,  ..., -1.1998e+00,\n",
            "          -1.6638e-01,  2.7011e-02],\n",
            "         [-5.2442e-01,  4.2906e-01, -2.3205e-01,  ..., -2.2718e-01,\n",
            "           1.2725e+00,  6.7703e-01],\n",
            "         [ 3.2405e-01,  9.4774e-01, -9.3867e-02,  ..., -6.7912e-01,\n",
            "           1.1141e+00,  2.8494e-01]]], device='cuda:0')\n",
            "\n",
            "\n",
            "4bit Simu: tensor([[[-1.4640e-01, -5.6264e-01,  4.8214e-01,  ..., -4.2120e-01,\n",
            "          -7.6057e-01, -1.0287e+00],\n",
            "         [ 6.7680e-01,  3.0616e-01,  5.1254e-01,  ...,  8.4372e-02,\n",
            "          -2.0434e-01, -3.5682e-01],\n",
            "         [ 8.5853e-01, -7.6380e-01,  7.9386e-01,  ..., -8.3073e-01,\n",
            "           4.6429e-01,  1.2012e+00],\n",
            "         ...,\n",
            "         [ 7.1918e-02, -1.8954e-03,  9.9408e-02,  ..., -6.5101e-02,\n",
            "          -5.7593e-01,  1.5086e-01],\n",
            "         [ 1.2258e-01, -6.1847e-01,  1.8685e-01,  ..., -4.1009e-02,\n",
            "           6.8894e-01,  2.1219e-01],\n",
            "         [ 2.7074e-02,  6.3513e-01, -2.8373e-01,  ..., -4.8454e-01,\n",
            "          -3.2065e-01,  2.8023e-01]],\n",
            "\n",
            "        [[ 6.9991e-02,  1.2140e-01, -5.8541e-02,  ...,  6.5306e-01,\n",
            "           3.5488e-01,  1.0413e+00],\n",
            "         [ 1.0711e+00, -3.6717e-01,  1.4761e-01,  ..., -2.2877e-01,\n",
            "          -1.5311e-01,  3.6130e-01],\n",
            "         [-1.5406e-01, -2.0638e-01,  6.7726e-01,  ..., -1.3541e-01,\n",
            "           1.7469e-01, -2.3793e-01],\n",
            "         ...,\n",
            "         [-2.0191e-01, -4.1277e-02, -3.3882e-01,  ..., -5.6098e-02,\n",
            "          -1.9925e-02,  1.2237e+00],\n",
            "         [-4.0981e-01, -8.4390e-01, -9.1751e-01,  ..., -1.0137e+00,\n",
            "           1.1952e-01,  8.5531e-02],\n",
            "         [-9.8648e-01, -4.3033e-01, -2.0876e-01,  ...,  1.8567e-01,\n",
            "          -8.5546e-01,  2.7223e-01]],\n",
            "\n",
            "        [[-3.6201e-01, -2.2249e-01, -5.5621e-01,  ..., -7.1098e-01,\n",
            "           6.4919e-01, -8.1554e-01],\n",
            "         [-4.4137e-01,  2.1476e-01,  6.0869e-01,  ...,  4.7673e-01,\n",
            "           1.2033e+00, -1.5546e-01],\n",
            "         [ 3.0050e-01,  1.4775e-01, -9.8640e-01,  ...,  6.0233e-01,\n",
            "          -3.2995e-01, -4.4346e-01],\n",
            "         ...,\n",
            "         [-6.0080e-01, -3.8042e-01,  2.1589e-02,  ..., -5.0794e-01,\n",
            "          -4.0836e-01,  4.8343e-01],\n",
            "         [-2.1173e-02,  4.2950e-01,  7.6862e-01,  ...,  6.1561e-02,\n",
            "          -1.7806e-01, -3.0516e-01],\n",
            "         [-1.9563e-01, -7.2439e-01,  8.5928e-02,  ..., -3.7635e-02,\n",
            "          -4.3968e-01,  1.9044e-01]],\n",
            "\n",
            "        [[ 3.9333e-01,  6.6054e-01,  1.1112e-01,  ..., -4.8132e-02,\n",
            "           2.1459e-01, -2.9658e-01],\n",
            "         [-2.9784e-01,  4.6780e-01,  4.1363e-01,  ...,  3.1948e-01,\n",
            "           1.4429e-01, -4.9933e-02],\n",
            "         [ 4.3910e-01, -7.2376e-01, -2.1189e-01,  ...,  2.2324e-01,\n",
            "           3.3604e-01,  7.7516e-02],\n",
            "         ...,\n",
            "         [ 8.2728e-01, -8.6034e-01,  3.5160e-01,  ...,  4.7945e-02,\n",
            "           1.6352e-01, -4.7542e-01],\n",
            "         [-2.0668e-01,  3.5940e-01, -4.3731e-01,  ...,  4.2798e-01,\n",
            "           7.2667e-01, -5.8964e-05],\n",
            "         [-1.3281e-01,  6.8486e-01, -8.1454e-01,  ...,  2.0984e-02,\n",
            "           1.0579e+00, -2.8602e-01]],\n",
            "\n",
            "        [[-3.6986e-01,  1.4345e-01,  7.3647e-01,  ...,  8.2241e-01,\n",
            "          -8.4097e-01,  2.1347e-02],\n",
            "         [ 6.7077e-01,  5.6097e-01, -1.4246e-02,  ...,  6.6031e-01,\n",
            "          -2.6654e-01, -3.7080e-01],\n",
            "         [-4.7001e-01, -1.1094e-01, -3.7124e-01,  ...,  4.5331e-01,\n",
            "           5.2761e-01, -2.4360e-01],\n",
            "         ...,\n",
            "         [-3.5322e-01,  2.4917e-01,  2.5883e-01,  ..., -1.7983e-01,\n",
            "          -1.9915e-01, -5.6554e-01],\n",
            "         [-1.6971e-01, -5.5248e-01,  1.0692e+00,  ...,  6.1852e-01,\n",
            "           2.8233e-01,  1.2946e-01],\n",
            "         [-2.3128e-03, -3.1779e-01, -8.9803e-02,  ..., -1.8567e+00,\n",
            "          -3.5158e-01, -2.1878e-01]]], device='cuda:0')\n",
            "4bit Kern: tensor([[[-1.4640e-01, -5.6264e-01,  4.8214e-01,  ..., -4.2120e-01,\n",
            "          -7.6057e-01, -1.0287e+00],\n",
            "         [ 6.7680e-01,  3.0616e-01,  5.1254e-01,  ...,  8.4372e-02,\n",
            "          -2.0434e-01, -3.5682e-01],\n",
            "         [ 8.5853e-01, -7.6380e-01,  7.9386e-01,  ..., -8.3073e-01,\n",
            "           4.6429e-01,  1.2012e+00],\n",
            "         ...,\n",
            "         [ 7.1918e-02, -1.8961e-03,  9.9408e-02,  ..., -6.5100e-02,\n",
            "          -5.7593e-01,  1.5086e-01],\n",
            "         [ 1.2258e-01, -6.1847e-01,  1.8685e-01,  ..., -4.1009e-02,\n",
            "           6.8894e-01,  2.1219e-01],\n",
            "         [ 2.7074e-02,  6.3513e-01, -2.8373e-01,  ..., -4.8454e-01,\n",
            "          -3.2065e-01,  2.8023e-01]],\n",
            "\n",
            "        [[ 6.9992e-02,  1.2140e-01, -5.8541e-02,  ...,  6.5306e-01,\n",
            "           3.5488e-01,  1.0413e+00],\n",
            "         [ 1.0711e+00, -3.6717e-01,  1.4761e-01,  ..., -2.2877e-01,\n",
            "          -1.5311e-01,  3.6130e-01],\n",
            "         [-1.5406e-01, -2.0638e-01,  6.7726e-01,  ..., -1.3542e-01,\n",
            "           1.7469e-01, -2.3793e-01],\n",
            "         ...,\n",
            "         [-2.0191e-01, -4.1277e-02, -3.3882e-01,  ..., -5.6098e-02,\n",
            "          -1.9925e-02,  1.2237e+00],\n",
            "         [-4.0981e-01, -8.4390e-01, -9.1751e-01,  ..., -1.0137e+00,\n",
            "           1.1952e-01,  8.5532e-02],\n",
            "         [-9.8648e-01, -4.3033e-01, -2.0876e-01,  ...,  1.8567e-01,\n",
            "          -8.5547e-01,  2.7223e-01]],\n",
            "\n",
            "        [[-3.6201e-01, -2.2249e-01, -5.5621e-01,  ..., -7.1097e-01,\n",
            "           6.4919e-01, -8.1554e-01],\n",
            "         [-4.4137e-01,  2.1476e-01,  6.0869e-01,  ...,  4.7673e-01,\n",
            "           1.2033e+00, -1.5546e-01],\n",
            "         [ 3.0050e-01,  1.4775e-01, -9.8640e-01,  ...,  6.0233e-01,\n",
            "          -3.2995e-01, -4.4346e-01],\n",
            "         ...,\n",
            "         [-6.0080e-01, -3.8042e-01,  2.1589e-02,  ..., -5.0794e-01,\n",
            "          -4.0836e-01,  4.8343e-01],\n",
            "         [-2.1173e-02,  4.2950e-01,  7.6862e-01,  ...,  6.1561e-02,\n",
            "          -1.7806e-01, -3.0516e-01],\n",
            "         [-1.9563e-01, -7.2439e-01,  8.5929e-02,  ..., -3.7635e-02,\n",
            "          -4.3967e-01,  1.9044e-01]],\n",
            "\n",
            "        [[ 3.9333e-01,  6.6054e-01,  1.1112e-01,  ..., -4.8130e-02,\n",
            "           2.1459e-01, -2.9658e-01],\n",
            "         [-2.9784e-01,  4.6780e-01,  4.1363e-01,  ...,  3.1948e-01,\n",
            "           1.4429e-01, -4.9932e-02],\n",
            "         [ 4.3910e-01, -7.2376e-01, -2.1189e-01,  ...,  2.2325e-01,\n",
            "           3.3604e-01,  7.7515e-02],\n",
            "         ...,\n",
            "         [ 8.2728e-01, -8.6034e-01,  3.5160e-01,  ...,  4.7945e-02,\n",
            "           1.6352e-01, -4.7542e-01],\n",
            "         [-2.0668e-01,  3.5940e-01, -4.3731e-01,  ...,  4.2798e-01,\n",
            "           7.2667e-01, -5.8905e-05],\n",
            "         [-1.3281e-01,  6.8486e-01, -8.1454e-01,  ...,  2.0984e-02,\n",
            "           1.0579e+00, -2.8602e-01]],\n",
            "\n",
            "        [[-3.6986e-01,  1.4345e-01,  7.3647e-01,  ...,  8.2241e-01,\n",
            "          -8.4097e-01,  2.1346e-02],\n",
            "         [ 6.7077e-01,  5.6097e-01, -1.4246e-02,  ...,  6.6031e-01,\n",
            "          -2.6654e-01, -3.7080e-01],\n",
            "         [-4.7001e-01, -1.1094e-01, -3.7124e-01,  ...,  4.5331e-01,\n",
            "           5.2761e-01, -2.4360e-01],\n",
            "         ...,\n",
            "         [-3.5322e-01,  2.4917e-01,  2.5883e-01,  ..., -1.7983e-01,\n",
            "          -1.9915e-01, -5.6554e-01],\n",
            "         [-1.6971e-01, -5.5247e-01,  1.0692e+00,  ...,  6.1852e-01,\n",
            "           2.8234e-01,  1.2946e-01],\n",
            "         [-2.3134e-03, -3.1779e-01, -8.9803e-02,  ..., -1.8567e+00,\n",
            "          -3.5158e-01, -2.1878e-01]]], device='cuda:0')\n",
            "\n",
            "\n",
            "8bit Simu: tensor([[[-0.3162,  0.7048,  0.4815,  ..., -1.1190, -0.7255,  0.1724],\n",
            "         [ 0.3559, -0.9010, -0.4878,  ..., -0.1646, -0.6955,  0.3869],\n",
            "         [-0.3506, -0.5035, -0.7371,  ..., -0.8451, -0.5335,  0.4489],\n",
            "         ...,\n",
            "         [ 0.5553, -0.8711,  0.6826,  ...,  0.6895, -0.0526,  1.1750],\n",
            "         [-0.9419,  0.2573,  0.4346,  ..., -0.4565, -0.0151,  0.0663],\n",
            "         [-0.0586, -0.4193,  0.3111,  ...,  0.0346, -0.1392,  0.8893]],\n",
            "\n",
            "        [[-0.0646,  0.4953, -0.2714,  ...,  0.0979, -0.4802, -0.4076],\n",
            "         [ 0.2489, -0.0200, -0.4859,  ...,  0.3135, -0.4524,  0.4561],\n",
            "         [-0.0104,  0.1974,  0.2174,  ...,  0.2035,  0.2346, -0.1584],\n",
            "         ...,\n",
            "         [-0.3910, -0.5744, -0.4245,  ..., -0.5078, -0.4684,  0.2324],\n",
            "         [ 0.8336,  0.3338, -0.1614,  ...,  0.0239, -0.5915,  0.2413],\n",
            "         [-0.1549, -0.3849, -0.6855,  ...,  0.3324, -0.3742, -0.4009]],\n",
            "\n",
            "        [[-1.3242, -0.0329,  0.8207,  ...,  0.1810, -0.2927, -0.7918],\n",
            "         [-0.7806,  0.6910, -0.2159,  ..., -0.1059, -0.4573,  1.1092],\n",
            "         [ 0.1141,  0.0044, -0.2258,  ...,  0.5995,  0.5472, -0.9247],\n",
            "         ...,\n",
            "         [-0.1791, -0.1923,  1.0860,  ...,  0.3575,  0.2683,  0.8351],\n",
            "         [ 0.2297,  0.7581, -0.7639,  ...,  0.8333,  0.4032, -0.2808],\n",
            "         [ 0.0784, -0.4314,  0.0711,  ...,  0.1267, -0.8539,  1.0037]],\n",
            "\n",
            "        [[-0.8863,  0.0896, -0.2352,  ...,  0.7560,  0.8233, -0.8695],\n",
            "         [ 0.5616, -0.0815,  0.4090,  ..., -0.3830,  0.3079, -0.0655],\n",
            "         [-0.0091,  0.5775,  0.4462,  ...,  0.0906, -0.1806, -0.2607],\n",
            "         ...,\n",
            "         [-0.2911,  0.2486,  0.1860,  ..., -0.5084,  0.0396,  0.1569],\n",
            "         [-0.2383,  0.0095,  0.4159,  ..., -0.4670,  0.2022, -1.0055],\n",
            "         [ 0.1850, -0.0688, -0.3260,  ...,  0.3312,  1.1255, -0.0204]],\n",
            "\n",
            "        [[ 0.3645, -0.3475, -0.9539,  ..., -0.3994, -0.1090, -0.2171],\n",
            "         [ 0.6272, -0.1347, -0.7509,  ..., -0.1021, -0.3665,  1.1693],\n",
            "         [ 1.1928, -0.2434,  0.3205,  ..., -0.7780, -0.5325,  0.0443],\n",
            "         ...,\n",
            "         [-0.1868, -0.1339, -0.0502,  ..., -0.0731,  0.5088, -0.5971],\n",
            "         [-0.2632,  0.8714,  0.3476,  ..., -0.2530, -0.6094,  0.3333],\n",
            "         [-0.6021,  0.4245,  0.5333,  ...,  0.3660,  1.3387,  0.0960]]],\n",
            "       device='cuda:0')\n",
            "8bit Kern: tensor([[[-0.3162,  0.7048,  0.4815,  ..., -1.1190, -0.7255,  0.1724],\n",
            "         [ 0.3559, -0.9010, -0.4878,  ..., -0.1646, -0.6955,  0.3869],\n",
            "         [-0.3506, -0.5035, -0.7371,  ..., -0.8451, -0.5335,  0.4489],\n",
            "         ...,\n",
            "         [ 0.5553, -0.8711,  0.6826,  ...,  0.6895, -0.0526,  1.1750],\n",
            "         [-0.9419,  0.2573,  0.4346,  ..., -0.4565, -0.0151,  0.0663],\n",
            "         [-0.0586, -0.4193,  0.3111,  ...,  0.0346, -0.1392,  0.8893]],\n",
            "\n",
            "        [[-0.0646,  0.4953, -0.2714,  ...,  0.0979, -0.4802, -0.4076],\n",
            "         [ 0.2489, -0.0200, -0.4859,  ...,  0.3135, -0.4524,  0.4561],\n",
            "         [-0.0104,  0.1974,  0.2174,  ...,  0.2035,  0.2346, -0.1584],\n",
            "         ...,\n",
            "         [-0.3910, -0.5744, -0.4245,  ..., -0.5078, -0.4684,  0.2324],\n",
            "         [ 0.8336,  0.3338, -0.1614,  ...,  0.0239, -0.5915,  0.2413],\n",
            "         [-0.1549, -0.3849, -0.6855,  ...,  0.3324, -0.3742, -0.4009]],\n",
            "\n",
            "        [[-1.3242, -0.0329,  0.8207,  ...,  0.1810, -0.2927, -0.7918],\n",
            "         [-0.7806,  0.6910, -0.2159,  ..., -0.1059, -0.4573,  1.1092],\n",
            "         [ 0.1141,  0.0044, -0.2258,  ...,  0.5995,  0.5472, -0.9247],\n",
            "         ...,\n",
            "         [-0.1791, -0.1923,  1.0860,  ...,  0.3575,  0.2683,  0.8351],\n",
            "         [ 0.2297,  0.7581, -0.7639,  ...,  0.8333,  0.4032, -0.2808],\n",
            "         [ 0.0784, -0.4314,  0.0711,  ...,  0.1267, -0.8539,  1.0037]],\n",
            "\n",
            "        [[-0.8863,  0.0896, -0.2352,  ...,  0.7560,  0.8233, -0.8695],\n",
            "         [ 0.5616, -0.0815,  0.4090,  ..., -0.3830,  0.3079, -0.0655],\n",
            "         [-0.0091,  0.5775,  0.4462,  ...,  0.0906, -0.1806, -0.2607],\n",
            "         ...,\n",
            "         [-0.2911,  0.2486,  0.1860,  ..., -0.5084,  0.0396,  0.1569],\n",
            "         [-0.2383,  0.0095,  0.4159,  ..., -0.4670,  0.2022, -1.0055],\n",
            "         [ 0.1850, -0.0688, -0.3260,  ...,  0.3312,  1.1256, -0.0204]],\n",
            "\n",
            "        [[ 0.3645, -0.3475, -0.9539,  ..., -0.3994, -0.1090, -0.2171],\n",
            "         [ 0.6272, -0.1347, -0.7509,  ..., -0.1021, -0.3665,  1.1693],\n",
            "         [ 1.1928, -0.2434,  0.3205,  ..., -0.7780, -0.5325,  0.0443],\n",
            "         ...,\n",
            "         [-0.1868, -0.1339, -0.0502,  ..., -0.0731,  0.5088, -0.5971],\n",
            "         [-0.2632,  0.8714,  0.3476,  ..., -0.2530, -0.6094,  0.3333],\n",
            "         [-0.6021,  0.4245,  0.5333,  ...,  0.3660,  1.3387,  0.0960]]],\n",
            "       device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "! python setup_cuda.py install && CUDA_VISIBLE_DEVICES=0 && python test_kernel.py\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0gYQ0aFSVTH"
      },
      "source": [
        "### 将BELLE-7B-gptq版本下载到colab\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7r0uotkjFjK8",
        "outputId": "5f351311-ba89-4173-cec3-f12bbfddc0df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updated git hooks.\n",
            "Git LFS initialized.\n",
            "fatal: destination path 'BELLE-LLAMA-7B-2M-gptq' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!git lfs install && git clone https://huggingface.co/BelleGroup/BELLE-LLAMA-7B-2M-gptq\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouZZilIOHr5Y",
        "outputId": "b60bdafd-aef2-4b1d-9a6c-fb40ea5bd89f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "config.json\t\tllama7b-2m-4bit-128g.pt  special_tokens_map.json\n",
            "generation_config.json\tllama7b-2m-8bit-128g.pt  tokenizer_config.json\n",
            "LICENSE\t\t\tREADME.md\t\t tokenizer.model\n"
          ]
        }
      ],
      "source": [
        "!ls BELLE-LLAMA-7B-2M-gptq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYKuTlQPSgIv"
      },
      "source": [
        "## BELLE **gptq推理**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lq3Sch7NJDc4",
        "outputId": "dfaba15d-5c98-4ce8-8e5c-1c0a3ad45f33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model ...\n",
            "Done.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "LlamaForCausalLM(\n",
              "  (model): LlamaModel(\n",
              "    (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n",
              "    (layers): ModuleList(\n",
              "      (0-31): 32 x LlamaDecoderLayer(\n",
              "        (self_attn): LlamaAttention(\n",
              "          (q_proj): QuantLinear()\n",
              "          (k_proj): QuantLinear()\n",
              "          (v_proj): QuantLinear()\n",
              "          (o_proj): QuantLinear()\n",
              "          (rotary_emb): LlamaRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): LlamaMLP(\n",
              "          (gate_proj): QuantLinear()\n",
              "          (down_proj): QuantLinear()\n",
              "          (up_proj): QuantLinear()\n",
              "          (act_fn): SiLUActivation()\n",
              "        )\n",
              "        (input_layernorm): LlamaRMSNorm()\n",
              "        (post_attention_layernorm): LlamaRMSNorm()\n",
              "      )\n",
              "    )\n",
              "    (norm): LlamaRMSNorm()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from gptq import *\n",
        "from modelutils import *\n",
        "from quant import *\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "DEV = torch.device('cuda:0')\n",
        "\n",
        "def get_llama(model):\n",
        "    import torch\n",
        "    def skip(*args, **kwargs):\n",
        "        pass\n",
        "    torch.nn.init.kaiming_uniform_ = skip\n",
        "    torch.nn.init.uniform_ = skip\n",
        "    torch.nn.init.normal_ = skip\n",
        "    from transformers import LlamaForCausalLM\n",
        "    model = LlamaForCausalLM.from_pretrained(model, torch_dtype='auto')\n",
        "    model.seqlen = 2048\n",
        "    return model\n",
        "\n",
        "def load_quant(model, checkpoint, wbits, groupsize):\n",
        "    from transformers import LlamaConfig, LlamaForCausalLM \n",
        "    config = LlamaConfig.from_pretrained(model)\n",
        "    def noop(*args, **kwargs):\n",
        "        pass\n",
        "    torch.nn.init.kaiming_uniform_ = noop \n",
        "    torch.nn.init.uniform_ = noop \n",
        "    torch.nn.init.normal_ = noop \n",
        "\n",
        "    torch.set_default_dtype(torch.half)\n",
        "    transformers.modeling_utils._init_weights = False\n",
        "    torch.set_default_dtype(torch.half)\n",
        "    model = LlamaForCausalLM(config)\n",
        "    torch.set_default_dtype(torch.float)\n",
        "    model = model.eval()\n",
        "    layers = find_layers(model)\n",
        "    for name in ['lm_head']:\n",
        "        if name in layers:\n",
        "            del layers[name]\n",
        "    make_quant(model, layers, wbits, groupsize)\n",
        "\n",
        "    print('Loading model ...')\n",
        "    if checkpoint.endswith('.safetensors'):\n",
        "        from safetensors.torch import load_file as safe_load\n",
        "        model.load_state_dict(safe_load(checkpoint))\n",
        "    else:\n",
        "        model.load_state_dict(torch.load(checkpoint))\n",
        "    model.seqlen = 2048\n",
        "    print('Done.')\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "class args:\n",
        "    model = \"BELLE-LLAMA-7B-2M-gptq\"\n",
        "    wbits = 4\n",
        "    groupsize = 128\n",
        "    load = \"BELLE-LLAMA-7B-2M-gptq/llama7b-2m-4bit-128g.pt\"\n",
        "    text = None\n",
        "    min_length = 10\n",
        "    max_length = 1024\n",
        "    top_p = 0.95\n",
        "    temperature = 0.7\n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "if type(args.load) is not str:\n",
        "    args.load = args.load.as_posix()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model = load_quant(args.model, args.load, args.wbits, args.groupsize)\n",
        "\n",
        "\n",
        "model.to(DEV)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEkYZgR2N5dm"
      },
      "outputs": [],
      "source": [
        "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
        "tokenizer = LlamaTokenizer.from_pretrained(\"BelleGroup/BELLE-LLAMA-7B-0.6M\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNk7kmfaOA3O"
      },
      "outputs": [],
      "source": [
        "def infer_text_gen(text):\n",
        "    inputs = f'Human: {text} \\n\\nAssistant:'\n",
        "    input_ids = tokenizer.encode(inputs, return_tensors=\"pt\").to(DEV)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        generated_ids = model.generate(\n",
        "            input_ids,\n",
        "            do_sample=True,\n",
        "            min_length=args.min_length,\n",
        "            max_length=args.max_length,\n",
        "            top_p=args.top_p,\n",
        "            temperature=args.temperature,\n",
        "        )\n",
        "\n",
        "    decode_text = tokenizer.decode([el.item() for el in generated_ids[0]])\n",
        "    decode_text = decode_text[len(inputs):]\n",
        "    decode_text = decode_text.replace(\"</s>\",\"\")\n",
        "    return decode_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yt822IK4OIpi",
        "outputId": "d6793643-0e29-4262-cc4f-afee62f83e87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ant:我叫Belle，我的名字代表着Bloom Enhanced Large Language model Engine，也就是说我是基于Bloom训练的大语言模型。\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(infer_text_gen(\"你是谁？\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuBIm4tcZ3yV",
        "outputId": "b1892784-f63d-42d6-8b71-afc8ed12d734"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ant:1. 充足的睡眠：每晚7-8小时的充足睡眠可以帮助我们恢复精力和焕发活力。\n",
            "2. 饮食健康：均衡的饮食可以提供身体所需的所有营养素，让我们保持精力充沛。\n",
            "3. 锻炼身体：运动可以提高我们的身体素质和免疫力，增强我们的精力和耐力。\n",
            "4. 减压放松：学习减压放松技巧可以帮助我们减少压力和焦虑，让我们保持精力充沛。\n",
            "5. 规律作息：保持规律的作息可以让我们的身体和大脑有一个良好的休息和恢复的时间，从而保持精力充沛。\n"
          ]
        }
      ],
      "source": [
        "print(infer_text_gen(\"怎么让自己精力充沛，列5点建议\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wno4FIAgZ8CI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}