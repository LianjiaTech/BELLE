# Usage

## Install conda environment

```bash
conda create -n belle python=3.10
conda activate belle
pip install -r requirements.txt
```

## Download dataset

```bash
python download_data.py
```

The open source data will be downloaded into folder belle_open_source_data/, and will be randomly split into training and validation sets.

## Train

```bash
bash run.sh
```

All hyperparameters are in the run.sh shell script

- modelname: The base models used for training include Llama(decapoda-research/llama-7b-hf), Bloom(bigscience/bloomz-7b1-mt), and so on.
- dataset_name: The Chinese dataset generated by Stanford Alpaca for reference. The address of the dataset: [Belle_open_source_1M](https://huggingface.co/datasets/BelleGroup/train_1M_CN), [Belle_open_source_0.5M](https://huggingface.co/datasets/BelleGroup/train_0.5M_CN)

## Evaluate

Assuming the model used in the training phase is bloomz-7b1-mt,, and the training data used is Belle_open_source_0.5M, you can directly run the following command to evaluate the model's generation results.

```bash
python evaluate.py --dev_file belle_open_source_data/Belle_open_source_0.5M.dev.json --model_name_or_path train_logs/bloomz-7b1-mt/Belle_open_source_0.5M_params_lr/ --output_file belle_open_source_data/Belle_open_source_0.5M.prediction.json
```
